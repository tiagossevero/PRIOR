# ğŸ“– Como Usar o Gerador de Data Schemas

Guia rÃ¡pido para gerar automaticamente os data schemas das tabelas GECOB.

---

## ğŸ¯ O que o script faz?

O script **`gerar_data_schemas.py`** gera automaticamente para cada tabela:

1. âœ… **DESCRIBE FORMATTED** - Schema completo da tabela
2. âœ… **SELECT * FROM ... LIMIT 10** - Amostra de 10 registros
3. âœ… **COUNT(*)** - Total de registros
4. âœ… Exporta tudo em **CSV, JSON e Markdown**

---

## ğŸ“‹ Tabelas Documentadas

O script processa estas 5 tabelas:

1. `gecob.prior_master_consolidado`
2. `gecob.prior_score_priorizacao`
3. `gecob.prior_score_componentes`
4. `gecob.prior_clusters_empresas`
5. `gecob.prior_outliers_identificados`

---

## ğŸš€ OpÃ§Ã£o 1: Usar o Notebook (RECOMENDADO)

### Passo a Passo:

1. **Abra o notebook:**
   ```bash
   jupyter notebook EXECUTAR_gerar_schemas.ipynb
   ```

2. **Execute as cÃ©lulas na ordem:**
   - CÃ©lula 1: Imports
   - CÃ©lula 2: Criar SparkSession
   - CÃ©lula 3: Verificar acesso Ã s tabelas
   - CÃ©lula 4: **EXECUTAR O GERADOR** â­
   - CÃ©lula 5+: Ver resultados

3. **Pronto!** Os arquivos estarÃ£o em `data_schemas/`

---

## ğŸ OpÃ§Ã£o 2: Usar Direto no Notebook (RÃ¡pido)

Se vocÃª jÃ¡ tem uma SparkSession ativa em um notebook:

```python
# Importar o script
import gerar_data_schemas

# Executar (assumindo que 'spark' estÃ¡ disponÃ­vel)
gerar_data_schemas.main(spark)
```

Ou usando `%run`:

```python
%run gerar_data_schemas.py
main(spark)
```

---

## ğŸ OpÃ§Ã£o 3: Script Python Standalone

Se preferir rodar como script Python:

```python
from pyspark.sql import SparkSession
import gerar_data_schemas

# Criar SparkSession
spark = SparkSession.builder \
    .appName("Gerar Data Schemas") \
    .enableHiveSupport() \
    .getOrCreate()

# Executar
gerar_data_schemas.main(spark)

# Finalizar
spark.stop()
```

---

## ğŸ“ Arquivos Gerados

ApÃ³s a execuÃ§Ã£o, vocÃª terÃ¡:

```
data_schemas/
â”œâ”€â”€ README.md                                         # Ãndice dos schemas
â”œâ”€â”€ data_schemas_completo.json                        # JSON consolidado
â”‚
â”œâ”€â”€ prior_master_consolidado_describe_formatted.csv   # Schema em CSV
â”œâ”€â”€ prior_master_consolidado_describe_formatted.json  # Schema em JSON
â”œâ”€â”€ prior_master_consolidado_describe_formatted.md    # Schema em Markdown
â”œâ”€â”€ prior_master_consolidado_sample_10.csv            # Amostra em CSV
â”œâ”€â”€ prior_master_consolidado_sample_10.json           # Amostra em JSON
â”œâ”€â”€ prior_master_consolidado_sample_10.md             # Amostra em Markdown
â”‚
â”œâ”€â”€ prior_score_priorizacao_describe_formatted.csv
â”œâ”€â”€ prior_score_priorizacao_describe_formatted.json
â”œâ”€â”€ prior_score_priorizacao_describe_formatted.md
â”œâ”€â”€ prior_score_priorizacao_sample_10.csv
â”œâ”€â”€ prior_score_priorizacao_sample_10.json
â”œâ”€â”€ prior_score_priorizacao_sample_10.md
â”‚
â”œâ”€â”€ prior_score_componentes_describe_formatted.csv
â”œâ”€â”€ prior_score_componentes_describe_formatted.json
â”œâ”€â”€ prior_score_componentes_describe_formatted.md
â”œâ”€â”€ prior_score_componentes_sample_10.csv
â”œâ”€â”€ prior_score_componentes_sample_10.json
â”œâ”€â”€ prior_score_componentes_sample_10.md
â”‚
â”œâ”€â”€ prior_clusters_empresas_describe_formatted.csv
â”œâ”€â”€ prior_clusters_empresas_describe_formatted.json
â”œâ”€â”€ prior_clusters_empresas_describe_formatted.md
â”œâ”€â”€ prior_clusters_empresas_sample_10.csv
â”œâ”€â”€ prior_clusters_empresas_sample_10.json
â”œâ”€â”€ prior_clusters_empresas_sample_10.md
â”‚
â”œâ”€â”€ prior_outliers_identificados_describe_formatted.csv
â”œâ”€â”€ prior_outliers_identificados_describe_formatted.json
â”œâ”€â”€ prior_outliers_identificados_describe_formatted.md
â”œâ”€â”€ prior_outliers_identificados_sample_10.csv
â”œâ”€â”€ prior_outliers_identificados_sample_10.json
â””â”€â”€ prior_outliers_identificados_sample_10.md
```

**Total:** 31 arquivos (1 README + 1 JSON consolidado + 6 arquivos Ã— 5 tabelas)

---

## ğŸ“Š Formatos DisponÃ­veis

### CSV (`.csv`)
- âœ… FÃ¡cil de importar no Excel, Google Sheets
- âœ… CodificaÃ§Ã£o UTF-8 com BOM
- âœ… Sem Ã­ndice

### JSON (`.json`)
- âœ… Estruturado para APIs e programaÃ§Ã£o
- âœ… Formato: `orient='records'`
- âœ… IndentaÃ§Ã£o legÃ­vel
- âœ… Caracteres especiais preservados

### Markdown (`.md`)
- âœ… VisualizaÃ§Ã£o bonita no GitHub
- âœ… Tabelas formatadas
- âœ… Timestamp de geraÃ§Ã£o

### JSON Consolidado
- âœ… Um Ãºnico arquivo com tudo
- âœ… Inclui metadata (timestamp, row count)
- âœ… Ideal para documentaÃ§Ã£o automÃ¡tica

---

## ğŸ”§ CustomizaÃ§Ãµes

### Alterar lista de tabelas

Edite o arquivo `gerar_data_schemas.py`:

```python
TABELAS = [
    'prior_master_consolidado',
    'prior_score_priorizacao',
    # Adicione ou remova tabelas aqui
    'minha_nova_tabela',
]
```

### Alterar database

```python
DATABASE = 'gecob'  # Altere para outro database
```

### Alterar nÃºmero de registros no sample

```python
# Na funÃ§Ã£o gerar_schema_tabela(), linha ~88:
df_sample = spark.sql(f"SELECT * FROM {DATABASE}.{tabela} LIMIT 10")
#                                                             ^^
#                                                       altere aqui
```

### Alterar diretÃ³rio de saÃ­da

```python
OUTPUT_DIR = 'data_schemas'  # Altere para outro diretÃ³rio
```

---

## âš ï¸ Troubleshooting

### Erro: "SparkSession nÃ£o encontrada"

**Problema:** Script executado fora de um ambiente Spark

**SoluÃ§Ã£o:** Use o notebook ou crie uma SparkSession antes

```python
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName("test").getOrCreate()
```

---

### Erro: "Table not found: gecob.prior_master_consolidado"

**Problema:** Tabela nÃ£o existe ou sem permissÃ£o

**SoluÃ§Ã£o:** Verifique se vocÃª tem acesso:

```python
spark.sql("SHOW DATABASES").show()
spark.sql("SHOW TABLES IN gecob").show()
```

---

### Erro: "Permission denied: data_schemas/"

**Problema:** Sem permissÃ£o para criar diretÃ³rio

**SoluÃ§Ã£o:** Execute em um diretÃ³rio onde vocÃª tem permissÃ£o de escrita

---

### Arquivo muito grande

**Problema:** Sample com muitas colunas gera arquivos grandes

**SoluÃ§Ã£o:**
1. Reduza o LIMIT (de 10 para 5, por exemplo)
2. Selecione apenas colunas especÃ­ficas
3. Use apenas formato CSV ou JSON (comente as outras linhas)

---

## ğŸ“ Suporte

Em caso de dÃºvidas:

1. Veja os exemplos nos notebooks `PRIOR COBR (6).ipynb`
2. Confira a documentaÃ§Ã£o do PySpark SQL
3. Verifique os logs de execuÃ§Ã£o no terminal

---

## âœ… Checklist de ExecuÃ§Ã£o

- [ ] Tenho acesso ao ambiente Spark
- [ ] Tenho permissÃ£o para ler as tabelas `gecob.*`
- [ ] Abri o notebook `EXECUTAR_gerar_schemas.ipynb`
- [ ] Executei a cÃ©lula de imports
- [ ] Criei a SparkSession
- [ ] Verifiquei acesso Ã s tabelas
- [ ] Executei o gerador
- [ ] Verifiquei os arquivos em `data_schemas/`
- [ ] Li o `data_schemas/README.md`

---

**GECOB - Sistema de PriorizaÃ§Ã£o de CobranÃ§a**
Receita Estadual de Santa Catarina
